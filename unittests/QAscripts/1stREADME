Support scripts for bulk testing TMMS on a FAME cluster.

Supporting environment variables:
---------------------------------

NETNAME
	The virtual bridge aginst which nodes are PXE booted.

FAM
	The file that acts like global NVM, set it up with fallocate.

Commands (alphabetical)
-----------------------

attachnode
	Bulk starts of FAME nodes have their consoles attached to a
	GNU screen(1) session named <NETNAME>.  This command takes
	a number from 1-40 and attaches to that console.

lxc-fixdev
	Used after starting an LXC container the first time to tweak a few
	things for FAME (especially libvirt bridges and vmdebootstrap)

octets2str
	Pass the client id octet stream from dhcpdump(1M) to see the
	ASCII string.

setnodes
	Takes a list of nodes or the word "all" and a manifest name
	(previously uploaded via "tm-manifest put ...").   Bind the
	specified nodes to that manifest.  Waits until all nodes
	show a final "ready" status.

startnode.arm
	Takes a number from 1-40 and PXE boots that node into the
	FAME setup specified by the environment variable NETNAME.

startnodes
	Takes a list of numbers 1-40 or the word "all" and gang starts
	a PXE boot for each.  The console goes into a screen session
	called NETNAME with a window named nodeXX.  Automatically
	invokes waitnodes.

waitnodes
	Takes a list of numbers 1-40 or the word "all" and waits for
	all the nodes on NETNAME to respond to sshd probes.  This
	can be called manually but is usually automatically invoked
	by startnodes.

Helper directories
------------------

dotssh/
	Minimal config files for a $HOME/.ssh directory to support
	phrase-less ssh (log, direct command execution, or ansible).
	Needs the "l4tm_pubkey" specified in the active manifest
	of a given node.

manifests/
	Sample manifests.  The "bender.json" only specifies a single
	extra package but that loads about eight dependent packages.


Setting up a new FAME system or LXC container UNVERIFIED
--------------------------------------------------------

1. Install L4TM on a fresh system or clone an L4TM LXC container.

2. apt-get install python3 git libvirt-bin virsh tm-librarian jq

3. Obtain a copy of TMCF for your TM instance and put it at /etc/tmconfig

   An easy way is through the librarian.  Copy these lines to "fame40.ini":

   [global]
   node_count = 40
   book_size_bytes = 8M
   nvm_size_per_node = 512B
   
   Then run "book_register.py -j fame40.ini > /tmp/tmconfig"

   finally "sudo mv /tmp/tmconfig /etc"

4. Set up a virtual bridge for the nodes to share.  The easiest way is
   through libvirt/virsh.   

   a. Pick a network/bridge name.  My favorite is "fame_arm" but we'll call
      it YOURNET.
   b. Pick a subnet for the nodes.  It needs to be unique on your system.
      libvirt default has already claimed 192.168.122.0/24.  I suggest you
      use 10.10.10.0/254 or pick a different RFC 1918 network.
   c. Put this in a file called YOURNET.xml:

	<network>
  	<name>YOURNET</name>
  	<forward mode='nat'>
    		<nat>
      			<port start='1024' end='65535'/>
    		</nat>
  	</forward>
  	<bridge name='YOURNET' stp='off' delay='0'/>
  	<ip address='10.10.10.254' netmask='255.255.255.0' />
	</network>

      I recommend the last legal address of your chosen network as the
      IP address assigned to the bridge.  From the node's point of view
      this is the ToRMS IP address.

    d. Adjust "YOURNET" in your file and name, then 

       sudo virsh net-define YOURNET.xml
       sudo virsh net-autostart YOURNET
       sudo virsh net-start YOURNET

    e. Find the running copy of dnsmasq assigned to YOURNET and kill it.
       You'll have to do this each time YOURNET is restarted (like
       after a reboot).

    f. export NETNAME=YOURNET

5. git clone https://github.hpe.com/hpelinux/manifesting.git

6. cd /where/ever/manifesting.  Follow the instructions in that README.
   As a result you should have an /etc/tmms file referencing your
   virtual bridge.

7. In a fresh window start "sudo tm-manifest-server --verbose"

   Verify there is a new dnsmasq running reference a config file whose
   name is "YOURNET.conf".

8. tm-manifest listnodes should reflect /etc/tmconfig

9. tm-manifest put manifests/something.json

10. Since this is FAME, you need a file for FAM.  If you use 8M books,
    512 books per node, 40 nodes, that's 160G of space.  IVSHMEM has
    to be a power of two so you need a 256G file.

    a. $ fallocate -l 256G /var/cache/FAM

    b. export FAM=/var/cache/FAM

11. setnodes all manname

12. startnodes all
